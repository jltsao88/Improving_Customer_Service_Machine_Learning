{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import warnings\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\jltsa\\\\Desktop\\\\Cust_complaints\\\\feature_sets\\\\ml_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>issue</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>company</th>\n",
       "      <th>submitted_via</th>\n",
       "      <th>timely_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>None</td>\n",
       "      <td>Billing statement</td>\n",
       "      <td>None</td>\n",
       "      <td>Year end summary provided by citi shows balanc...</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>Web</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Other (i.e. phone, health club, etc.)</td>\n",
       "      <td>Disclosure verification of debt</td>\n",
       "      <td>Not given enough info to verify debt</td>\n",
       "      <td>I received a letter from a debt collector clai...</td>\n",
       "      <td>Amsher Collection Services, Inc.</td>\n",
       "      <td>Web</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Other (i.e. phone, health club, etc.)</td>\n",
       "      <td>Cont'd attempts collect debt not owed</td>\n",
       "      <td>Debt is not mine</td>\n",
       "      <td>I HAVE SUBMITTED COMPLAINTS TO OF UPSTATE NY C...</td>\n",
       "      <td>Credit Protection Association, L.P.</td>\n",
       "      <td>Web</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Other (i.e. phone, health club, etc.)</td>\n",
       "      <td>Cont'd attempts collect debt not owed</td>\n",
       "      <td>Debt resulted from identity theft</td>\n",
       "      <td>has accounts in my name that were fraudulently...</td>\n",
       "      <td>Convergent Resources, Inc.</td>\n",
       "      <td>Web</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>None</td>\n",
       "      <td>Late fee</td>\n",
       "      <td>None</td>\n",
       "      <td>When making online through personal bank payme...</td>\n",
       "      <td>SYNCHRONY FINANCIAL</td>\n",
       "      <td>Web</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           product                            sub_product  \\\n",
       "0      Credit card                                   None   \n",
       "1  Debt collection  Other (i.e. phone, health club, etc.)   \n",
       "2  Debt collection  Other (i.e. phone, health club, etc.)   \n",
       "3  Debt collection  Other (i.e. phone, health club, etc.)   \n",
       "4      Credit card                                   None   \n",
       "\n",
       "                                   issue  \\\n",
       "0                      Billing statement   \n",
       "1        Disclosure verification of debt   \n",
       "2  Cont'd attempts collect debt not owed   \n",
       "3  Cont'd attempts collect debt not owed   \n",
       "4                               Late fee   \n",
       "\n",
       "                              sub_issue  \\\n",
       "0                                  None   \n",
       "1  Not given enough info to verify debt   \n",
       "2                      Debt is not mine   \n",
       "3     Debt resulted from identity theft   \n",
       "4                                  None   \n",
       "\n",
       "                        consumer_complaint_narrative  \\\n",
       "0  Year end summary provided by citi shows balanc...   \n",
       "1  I received a letter from a debt collector clai...   \n",
       "2  I HAVE SUBMITTED COMPLAINTS TO OF UPSTATE NY C...   \n",
       "3  has accounts in my name that were fraudulently...   \n",
       "4  When making online through personal bank payme...   \n",
       "\n",
       "                               company submitted_via  timely_response  \n",
       "0                       CITIBANK, N.A.           Web             True  \n",
       "1     Amsher Collection Services, Inc.           Web             True  \n",
       "2  Credit Protection Association, L.P.           Web             True  \n",
       "3           Convergent Resources, Inc.           Web             True  \n",
       "4                  SYNCHRONY FINANCIAL           Web             True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 383840 entries, 0 to 383839\n",
      "Data columns (total 7 columns):\n",
      "product                         383840 non-null object\n",
      "sub_product                     383840 non-null object\n",
      "issue                           383840 non-null object\n",
      "sub_issue                       383840 non-null object\n",
      "consumer_complaint_narrative    383840 non-null object\n",
      "company                         383840 non-null object\n",
      "submitted_via                   383840 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 20.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timely_response\n",
       "True     372452\n",
       "False     11388\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('timely_response').count()['company'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029668611921634013"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11388/(372452+11388)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data has only around 3% of the labels calssified as False or not responsign appropriately in time, accuracy will be a bad metric of success.  For instance, the model can classify everything as True and have an accuracy rate of 97%.\n",
    "\n",
    "Instead, we can use log loss as a measure of success.  It is actually a measure of error.  In this case we want log loss to be as small as possible as opposed to accuracy.\n",
    "\n",
    "Oen take away is that it isbetter to be less confident than confident and wrong about a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log loss can be calculated with numpy\n",
    "def compute_log_loss(predicted, actual, eps=1e-14):\n",
    "    \"\"\"\n",
    "    predicted: probabilities as floats between 0 and 1\n",
    "    actual: binary labels, 0=no or 1=yes\n",
    "    eps: log(0) is inf, need to offset predicted values by eps from 0 to 1\n",
    "    \"\"\"\n",
    "    predicted = np.clip(predicted, eps, 1- eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted) + (1 - actual)\n",
    "              * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994046"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are saying we are predicting the value is 1 with 90% probability\n",
    "#But the the actual label is 0\n",
    "compute_log_loss(predicted=0.9, actual=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994046"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scikit-learn implementation\n",
    "log_loss([0,1], [0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting 50% probability that value is 1\n",
    "#Actual label is 1\n",
    "compute_log_loss(0.5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Features to Engineer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A count for number of exclamation points in a narrative - could be an indicator of how important a claim can be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted above the False label only appears in about 3% of our data.  We need to make sure the training and test splits include these labels.  We can use StratifiedShuffleSplit from SciKitLearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "We did some preprocessing already on the data.  Now, we will do further preprocessing to get our data for machine learning.  For this project, use a bag of words representation for NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spacy tokenizer\n",
    "spacy.load('en_core_web_sm')\n",
    "lemmatizer = spacy.lang.en.English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used for testing output of vectorizer\n",
    "def wm2df(wm, feat_names):\n",
    "    #create a dataframe from a word matrix\n",
    "    # create an index for each row\n",
    "    doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(wm)]\n",
    "    df = pd.DataFrame(data=wm.toarray(), index=doc_names,\n",
    "                      columns=feat_names)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>field surprisingly</th>\n",
       "      <th>high</th>\n",
       "      <th>high speed</th>\n",
       "      <th>petro</th>\n",
       "      <th>petro vend</th>\n",
       "      <th>run</th>\n",
       "      <th>run field</th>\n",
       "      <th>speed</th>\n",
       "      <th>speed petro</th>\n",
       "      <th>surprisingly</th>\n",
       "      <th>surprisingly high</th>\n",
       "      <th>vend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      field  field surprisingly  high  high speed  petro  petro vend  run  \\\n",
       "Doc0      1                   1     1           1      1           1    1   \n",
       "\n",
       "      run field  speed  speed petro  surprisingly  surprisingly high  vend  \n",
       "Doc0          1      1            1             1                  1     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Customizing Vectorizers\n",
    "def my_tokenizer(doc):\n",
    "    tokens = lemmatizer(doc)\n",
    "    return([token.lemma_ for token in tokens])\n",
    "\n",
    "custom_vec = CountVectorizer(tokenizer=my_tokenizer,\n",
    "                             ngram_range=(1,2),\n",
    "                             stop_words='english')\n",
    "\n",
    "cwm = custom_vec.fit_transform(['He ran through the Fields and surprisingly high speeds Petro vend'])\n",
    "tokens = custom_vec.get_feature_names()\n",
    "wm2df(cwm, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels we want to predict\n",
    "labels = df['timely_response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the label for the Data so we can pull out only the features\n",
    "df = df.drop('timely_response', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all features but complaint narrative to dummy variables\n",
    "cats = ['product', 'sub_product', 'issue', 'sub_issue', 'company', 'submitted_via']\n",
    "\n",
    "#df = pd.get_dummies(df, columns=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Function transformer to create steps to vectorize narrative data\n",
    "def get_narr(df):\n",
    "    return df['consumer_complaint_narrative']\n",
    "\n",
    "#grabs the complaint narrative data for use in pipe line\n",
    "get_narr_pl = FunctionTransformer(get_narr, validate=False)\n",
    "\n",
    "def get_cats(df):\n",
    "    return df[['product', 'sub_product', 'issue', 'sub_issue', 'company', 'submitted_via']]\n",
    "\n",
    "get_cats_pl = FunctionTransformer(get_cats, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "             ('union', FeatureUnion(\n",
    "                  transformer_list = [\n",
    "                      ('cat_features', Pipeline([\n",
    "                          ('selector', get_cats_pl),\n",
    "                          ('one_hot_encode', OneHotEncoder(handle_unknown='ignore'))\n",
    "                      ])),\n",
    "                      ('narr_feature', Pipeline([\n",
    "                          ('selector', get_narr_pl),\n",
    "                          ('vecorizer', custom_vec)\n",
    "                      ]))\n",
    "                  ])),\n",
    "             ('clf', RandomForestClassifier())\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = pl.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36420188638053297"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test[:100], proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "             ('union', FeatureUnion(\n",
    "                  transformer_list = [\n",
    "                      ('cat_features', Pipeline([\n",
    "                          ('selector', get_cats_pl),\n",
    "                          ('one_hot_encode', OneHotEncoder(handle_unknown='ignore'))\n",
    "                      ])),\n",
    "                      ('narr_feature', Pipeline([\n",
    "                          ('selector', get_narr_pl),\n",
    "                          ('vecorizer', custom_vec)\n",
    "                      ]))\n",
    "                  ])),\n",
    "             ('clf', LogisticRegression())\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('union',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('cat_features',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  FunctionTransformer(accept_sparse=False,\n",
       "                                                                                      check_inverse=True,\n",
       "                                                                                      func=<function get_cats at 0x00000213E1FDF048>,\n",
       "                                                                                      inv_kw_args=None,\n",
       "                                                                                      inverse_func=None,\n",
       "                                                                                      kw_args=None,\n",
       "                                                                                      pass_y='deprecated',\n",
       "                                                                                      validate=False)),\n",
       "                                                                 ('one_hot_encode',\n",
       "                                                                  OneHotEn...\n",
       "                                                                                  tokenizer=<function my_tokenizer at 0x00000213BA5682F0>,\n",
       "                                                                                  vocabulary=None))],\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.fit(X_train[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06264046451248427"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = pl.predict_proba(X_test[:100])\n",
    "log_loss(y_test[:100], proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
